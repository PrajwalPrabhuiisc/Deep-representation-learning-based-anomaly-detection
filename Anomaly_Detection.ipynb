# The  code performs deep representation learning based anomaly detection. This is a comprehensive pipeline to evaluate the anomaly seen in the structure

import numpy as np
import re
import os
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.models import Sequential, load_model, Model
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
from itertools import product
from sklearn.metrics import silhouette_score
from sklearn.decomposition import PCA

# --------------------------
# Global Save Folder
# --------------------------
SAVE_DIR = "results"
os.makedirs(SAVE_DIR, exist_ok=True)

# --------------------------
# Helper Function: Relative Trend Calculation
# --------------------------
def compute_relative_trend(errors, fraction=0.1):
    """
    Compute the relative trend for a series of errors as the percentage change
    between the average error of the first and last fraction of the data.
    """
    n = len(errors)
    if n < 2:
        return 0.0
    k = max(1, int(n * fraction))
    start_mean = np.mean(errors[:k])
    end_mean = np.mean(errors[-k:])
    if start_mean == 0:
        return 0.0
    return (end_mean - start_mean) / start_mean

# --------------------------
# New Visualization Functions
# --------------------------
def visualize_training_history(history, sensor_name, save_fig=False, save_dir=SAVE_DIR):
    """
    Plot the training and validation loss over epochs.
    """
    plt.figure(figsize=(10, 6))
    plt.plot(history.history.get('loss', []), label='Training Loss', marker='o')
    plt.plot(history.history.get('val_loss', []), label='Validation Loss', marker='o')
    plt.title(f"Training History for {sensor_name}")
    plt.xlabel("Epochs")
    plt.ylabel("Loss")
    plt.legend()
    plt.grid(True)
    if save_fig:
        save_path = os.path.join(save_dir, f"{sensor_name.replace(' ', '_')}_training_history.jpg")
        plt.savefig(save_path, format='jpg')
    plt.show()

def visualize_latent_space(autoencoder, data, anomalies, sensor_name, save_fig=False, save_dir=SAVE_DIR):
    """
    Extract and visualize the latent space representation from the autoencoder.
    We assume that the bottleneck (latent) representation is the output of layer 4.
    Then, we use PCA to project it to 2 dimensions for visualization.
    The plot shows data points colored by their anomaly flag.
    """
    # Create a new model that outputs the latent representation.
    # (Adjust the layer index if your architecture changes.)
    latent_layer_index = 4
    intermediate_model = Model(inputs=autoencoder.input, outputs=autoencoder.layers[latent_layer_index].output)
    latent_repr = intermediate_model.predict(data)
    
    # Use PCA to reduce the latent space to 2 dimensions.
    pca = PCA(n_components=2)
    latent_2d = pca.fit_transform(latent_repr)
    
    plt.figure(figsize=(10, 8))
    scatter = plt.scatter(latent_2d[:, 0], latent_2d[:, 1], c=anomalies.astype(int), cmap='viridis', s=40)
    plt.title(f"2D PCA Projection of Latent Space for {sensor_name}")
    plt.xlabel("PC1")
    plt.ylabel("PC2")
    plt.colorbar(scatter, ticks=[0, 1], label="Anomaly Flag")
    plt.grid(True)
    if save_fig:
        save_path = os.path.join(save_dir, f"{sensor_name.replace(' ', '_')}_latent_space.jpg")
        plt.savefig(save_path, format='jpg')
    plt.show()

# --------------------------
# Situation Awareness Module
# --------------------------
class SituationAwareness:
    @staticmethod
    def calculate_metrics(reconstruction_errors, anomalies, threshold):
        """
        Calculate performance metrics based on reconstruction errors and anomaly flags.
        Uses a threshold-independent measure (silhouette score) to assess cluster separation.
        """
        rel_trend = compute_relative_trend(reconstruction_errors, fraction=0.1)
        risk_level = np.mean(np.maximum(reconstruction_errors - threshold, 0) / (threshold + 1e-8))
        try:
            sil_score = silhouette_score(reconstruction_errors.reshape(-1, 1), anomalies.astype(int))
        except Exception:
            sil_score = -1.0

        metrics = {
            'anomaly_rate': np.mean(anomalies),
            'error_mean': np.mean(reconstruction_errors),
            'error_std': np.std(reconstruction_errors),
            'risk_level': risk_level,
            'trend': rel_trend,
            'threshold': threshold,
            'silhouette_score': sil_score
        }
        return metrics

    @staticmethod
    def visualize_results(test_data, reconstructed, reconstruction_errors, anomalies,
                            sensor_name, metrics, training_params=None, sequence_length=50, 
                            save_fig=False, save_dir=SAVE_DIR):
        """
        Create a multi-panel figure showing:
          - Time series for X (original vs. reconstructed)
          - Time series for Y (original vs. reconstructed)
          - Scatter plot of (X, Y) colored by anomaly flag
          - Reconstruction error trend with relative trend annotation
          - A text box with computed model metrics
          - A text box with training parameters
        """
        if test_data.shape[0] == len(anomalies):
            adjusted_test_data = test_data
        else:
            adjusted_test_data = test_data[sequence_length - 1:]
        
        fig = plt.figure(figsize=(18, 12))
        
        # Panel 1: X-direction
        ax1 = fig.add_subplot(2, 3, 1)
        ax1.plot(adjusted_test_data[:, 0], label='Original X', color='tab:blue')
        ax1.plot(reconstructed[:, 0], label='Reconstructed X', linestyle='--', color='tab:cyan')
        ax1.set_title(f'{sensor_name} - X Direction')
        ax1.legend()
        
        # Panel 2: Y-direction
        ax2 = fig.add_subplot(2, 3, 2)
        ax2.plot(adjusted_test_data[:, 1], label='Original Y', color='tab:orange')
        ax2.plot(reconstructed[:, 1], label='Reconstructed Y', linestyle='--', color='tab:red')
        ax2.set_title(f'{sensor_name} - Y Direction')
        ax2.legend()
        
        # Panel 3: Anomaly Distribution Scatter Plot
        ax3 = fig.add_subplot(2, 3, 3)
        scatter = ax3.scatter(adjusted_test_data[:, 0], adjusted_test_data[:, 1],
                              c=anomalies.astype(int), cmap='viridis', s=40)
        ax3.set_title('Anomaly Distribution')
        plt.colorbar(scatter, ax=ax3, ticks=[0, 1])
        
        # Panel 4: Reconstruction Error Trend
        ax4 = fig.add_subplot(2, 3, 4)
        ax4.plot(reconstruction_errors, label='Reconstruction Error', color='tab:purple')
        ax4.axhline(metrics['error_mean'], color='tab:gray', linestyle='--', label='Mean Error')
        ax4.set_title('Reconstruction Error Trend (Original Scale)')
        ax4.text(0.05, 0.9, f"Relative Trend: {metrics['trend']*100:.2f}%", transform=ax4.transAxes,
                 bbox=dict(facecolor='white', alpha=0.8))
        ax4.legend()
        
        # Panel 5: Model Metrics
        ax5 = fig.add_subplot(2, 3, 5)
        ax5.axis('off')
        textstr = (f"Anomaly Rate: {metrics['anomaly_rate']:.2%}\n"
                   f"Risk Level: {metrics['risk_level']:.4f}\n"
                   f"Error Mean: {metrics['error_mean']:.4f}\n"
                   f"Error Std: {metrics['error_std']:.4f}\n"
                   f"Relative Trend: {metrics['trend']*100:.2f}%\n"
                   f"Threshold: {metrics['threshold']:.4f}\n"
                   f"Silhouette Score: {metrics['silhouette_score']:.4f}")
        ax5.text(0.05, 0.5, textstr, fontsize=12, verticalalignment='center',
                 bbox=dict(facecolor='white', alpha=0.8))
        ax5.set_title('Model Metrics')
        
        # Panel 6: Training Parameters
        ax6 = fig.add_subplot(2, 3, 6)
        ax6.axis('off')
        if training_params is not None:
            train_str = "Training Parameters:\n"
            for key, value in training_params.items():
                train_str += f"{key}: {value}\n"
        else:
            train_str = "Training Parameters: Not Available"
        ax6.text(0.05, 0.5, train_str, fontsize=12, verticalalignment='center',
                 bbox=dict(facecolor='white', alpha=0.8))
        ax6.set_title('Training Parameters')
        
        fig.suptitle(f'Anomaly Detection Results for {sensor_name}', fontsize=18)
        plt.tight_layout(rect=[0, 0.03, 1, 0.95])
        
        if save_fig:
            save_path = os.path.join(save_dir, f"{sensor_name.replace(' ', '_')}_results.jpg")
            fig.savefig(save_path, format='jpg')
        plt.show()

# --------------------------
# Helper Functions for Data Handling and Modeling
# --------------------------
def parse_sensor_data(file_path, directions=['X', 'Y']):
    sensor_data = {f'Sensor {i+1}': {d: [] for d in directions} for i in range(4)}
    with open(file_path, 'r') as file:
        for line in file:
            match = re.search(
                r"Sensor 1 - X: ([\d\.\-]+) Y: ([\d\.\-]+).*"
                r"Sensor 2 - X: ([\d\.\-]+) Y: ([\d\.\-]+).*"
                r"Sensor 3 - X: ([\d\.\-]+) Y: ([\d\.\-]+).*"
                r"Sensor 4 - X: ([\d\.\-]+) Y: ([\d\.\-]+)",
                line
            )
            if match:
                for i, sensor in enumerate(['Sensor 1', 'Sensor 2', 'Sensor 3', 'Sensor 4'], 1):
                    sensor_data[sensor]['X'].append(float(match.group(2 * i - 1)))
                    sensor_data[sensor]['Y'].append(float(match.group(2 * i)))
    return {sensor: np.array([data['X'], data['Y']]).T for sensor, data in sensor_data.items()}

def normalize_data(train_data, test_data):
    scaler = StandardScaler()
    scaler.fit(train_data.reshape(-1, train_data.shape[-1]))
    normalized_train = scaler.transform(train_data.reshape(-1, train_data.shape[-1])).reshape(train_data.shape)
    normalized_test = scaler.transform(test_data.reshape(-1, test_data.shape[-1])).reshape(test_data.shape)
    return normalized_train, normalized_test, scaler

def build_autoencoder_with_params(input_shape, dense_units=64, dropout_rate=0.2, learning_rate=0.0003):
    model = Sequential([
        Dense(dense_units, activation='relu', input_shape=(input_shape,)),
        Dropout(dropout_rate),
        Dense(dense_units // 2, activation='relu'),
        Dropout(dropout_rate),
        Dense(dense_units // 4, activation='relu'),  # Latent representation layer
        Dense(dense_units // 2, activation='relu'),
        Dropout(dropout_rate),
        Dense(dense_units, activation='relu'),
        Dense(input_shape)
    ])
    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error')
    return model

def plot_reconstruction_errors(test_data, reconstructed_data, sensor_name, save_fig=False, save_dir=SAVE_DIR):
    plt.figure(figsize=(15, 10))
    error_x = np.square(test_data[:, 0] - reconstructed_data[:, 0])
    error_y = np.square(test_data[:, 1] - reconstructed_data[:, 1])
    plt.subplot(2, 2, 1)
    plt.plot(test_data[:, 0], label='Original X', color='blue')
    plt.plot(reconstructed_data[:, 0], label='Reconstructed X', color='red')
    plt.title(f'{sensor_name} X Direction')
    plt.legend()
    plt.subplot(2, 2, 2)
    plt.plot(test_data[:, 1], label='Original Y', color='blue')
    plt.plot(reconstructed_data[:, 1], label='Reconstructed Y', color='red')
    plt.title(f'{sensor_name} Y Direction')
    plt.legend()
    plt.subplot(2, 2, 3)
    plt.plot(error_x, label='X Reconstruction Error', color='green')
    plt.title(f'{sensor_name} X Reconstruction Error')
    plt.legend()
    plt.subplot(2, 2, 4)
    plt.plot(error_y, label='Y Reconstruction Error', color='green')
    plt.title(f'{sensor_name} Y Reconstruction Error')
    plt.legend()
    plt.tight_layout()
    if save_fig:
        save_path = os.path.join(save_dir, f"{sensor_name.replace(' ', '_')}_reconstruction_errors.jpg")
        plt.savefig(save_path, format='jpg')
    plt.show()

# --------------------------
# Anomaly Detection Class with Training History Capture
# --------------------------
class AnomalyDetector:
    """
    Encapsulates the anomaly detection pipeline for a single sensor.
    Optionally tunes hyperparameters and saves/loads the trained model.
    Also captures training history.
    """
    def __init__(self, sensor_name, train_data, test_data, tune=False, param_grid=None):
        self.sensor_name = sensor_name
        self.train_data = train_data
        self.test_data = test_data
        self.tune = tune
        self.param_grid = param_grid
        self.autoencoder = None
        self.normalized_train = None
        self.normalized_test = None
        self.scaler = None
        self.threshold = None
        self.anomalies = None
        self.reconstruction_errors = None
        self.train_errors = None
        self.best_params = None
        self.history = None  # To store training history

    def normalize_data(self):
        self.normalized_train, self.normalized_test, self.scaler = normalize_data(self.train_data, self.test_data)

    def build_and_train_model(self, dense_units=64, dropout_rate=0.2, learning_rate=0.0003, epochs=300):
        self.autoencoder = build_autoencoder_with_params(
            input_shape=self.train_data.shape[-1],
            dense_units=dense_units,
            dropout_rate=dropout_rate,
            learning_rate=learning_rate
        )
        train_data_flat = self.normalized_train.reshape(-1, self.normalized_train.shape[-1])
        early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)
        self.history = self.autoencoder.fit(
            train_data_flat, train_data_flat,
            epochs=epochs, batch_size=32, validation_split=0.2,
            callbacks=[early_stop], verbose=0
        )
        self.best_params = {
            "dense_units": dense_units,
            "dropout_rate": dropout_rate,
            "learning_rate": learning_rate,
            "epochs": epochs
        }

    def tune_hyperparameters(self):
        best_sil = -np.inf
        best_params = {}
        best_model = None

        if self.param_grid is None:
            self.param_grid = {
                'dense_units': [64, 128],
                'dropout_rate': [0.2, 0.3],
                'learning_rate': [0.0003, 0.001],
                'epochs': [150, 300]
            }

        holdout_fraction = 0.2
        n_samples = self.normalized_train.shape[0]
        holdout_size = int(n_samples * holdout_fraction)
        tuning_holdout = self.normalized_train[-holdout_size:]
        tuning_train = self.normalized_train[:-holdout_size]

        # Dummy surrogate ground truth
        holdout_pred = np.mean(np.square(tuning_holdout - tuning_holdout), axis=1)
        holdout_ground_truth = holdout_pred > (np.mean(holdout_pred) + 2 * np.std(holdout_pred))

        for params in product(*self.param_grid.values()):
            param_dict = dict(zip(self.param_grid.keys(), params))
            print(f"Tuning {self.sensor_name} with params: {param_dict}")
            model = build_autoencoder_with_params(
                input_shape=self.train_data.shape[-1],
                dense_units=param_dict['dense_units'],
                dropout_rate=param_dict['dropout_rate'],
                learning_rate=param_dict['learning_rate']
            )
            tuning_train_flat = tuning_train.reshape(-1, tuning_train.shape[-1])
            early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
            history = model.fit(
                tuning_train_flat, tuning_train_flat,
                epochs=param_dict['epochs'], batch_size=32, validation_split=0.2,
                callbacks=[early_stop], verbose=0
            )
            tuning_holdout_flat = tuning_holdout.reshape(-1, tuning_holdout.shape[-1])
            holdout_reconstructed = model.predict(tuning_holdout_flat)
            reconstruction_errors = np.mean(np.square(tuning_holdout - holdout_reconstructed), axis=1)
            threshold = np.percentile(reconstruction_errors, 95)
            anomalies = reconstruction_errors > threshold
            try:
                sil_score = silhouette_score(reconstruction_errors.reshape(-1, 1), anomalies.astype(int))
            except Exception:
                sil_score = -1.0
            print(f"Params: {param_dict} achieved silhouette score: {sil_score:.6f}")
            if sil_score > best_sil:
                best_sil = sil_score
                best_params = param_dict
                best_model = model

        print(f"Best params for {self.sensor_name}: {best_params} with silhouette score: {best_sil:.6f}")
        self.best_params = best_params
        self.autoencoder = best_model

    def build_and_train(self):
        if self.tune:
            self.tune_hyperparameters()
        else:
            self.build_and_train_model()

    def detect_anomalies(self):
        normalized_reconstructed = self.autoencoder.predict(
            self.normalized_test.reshape(-1, self.normalized_test.shape[-1])
        )
        reconstructed_original = self.scaler.inverse_transform(normalized_reconstructed)
        original_reconstruction_errors = np.mean(np.square(self.test_data - reconstructed_original), axis=1)

        normalized_train_pred = self.autoencoder.predict(
            self.normalized_train.reshape(-1, self.normalized_train.shape[-1])
        )
        reconstructed_train_original = self.scaler.inverse_transform(normalized_train_pred)
        original_train_errors = np.mean(np.square(self.train_data - reconstructed_train_original), axis=1)

        threshold_original = np.percentile(original_train_errors, 95)
        anomalies = original_reconstruction_errors > threshold_original

        self.reconstruction_errors = original_reconstruction_errors
        self.train_errors = original_train_errors
        self.threshold = threshold_original
        self.anomalies = anomalies

        return reconstructed_original

    def run(self):
        self.normalize_data()
        model_filename = f"{self.sensor_name.replace(' ', '_')}_autoencoder.h5"
        if os.path.exists(model_filename):
            print(f"Loading saved model for {self.sensor_name} from {model_filename}")
            self.autoencoder = load_model(model_filename)
            self.best_params = {"info": "Model loaded from disk"}
        else:
            print(f"No saved model found for {self.sensor_name}. Training new model...")
            if self.tune:
                self.tune_hyperparameters()
            else:
                self.build_and_train_model()
            self.autoencoder.save(model_filename)
            print(f"Model saved for {self.sensor_name} to {model_filename}")
        return self.detect_anomalies()

# --------------------------
# Cross-Sensor Correlation and Malfunction Detection
# --------------------------
def compute_sensor_cross_correlation(sensor_results):
    sensor_names = list(sensor_results.keys())
    num_sensors = len(sensor_names)
    corr_matrix = np.zeros((num_sensors, num_sensors))
    for i in range(num_sensors):
        for j in range(num_sensors):
            errors_i = sensor_results[sensor_names[i]]['detector'].reconstruction_errors
            errors_j = sensor_results[sensor_names[j]]['detector'].reconstruction_errors
            corr_matrix[i, j] = np.corrcoef(errors_i, errors_j)[0, 1]
    return sensor_names, corr_matrix

def plot_cross_correlation(sensor_names, corr_matrix, save_fig=False, save_dir=SAVE_DIR):
    plt.figure(figsize=(8, 6))
    im = plt.imshow(corr_matrix, cmap='coolwarm', vmin=-1, vmax=1)
    plt.colorbar(im, fraction=0.046, pad=0.04)
    plt.xticks(np.arange(len(sensor_names)), sensor_names)
    plt.yticks(np.arange(len(sensor_names)), sensor_names)
    plt.title("Cross-Correlation of Sensor Reconstruction Errors")
    if save_fig:
        save_path = os.path.join(save_dir, "cross_correlation.jpg")
        plt.savefig(save_path, format='jpg')
    plt.show()

def detect_malfunctioning_sensor(corr_matrix, sensor_names, threshold_diff=0.2):
    num_sensors = len(sensor_names)
    avg_corr = []
    for i in range(num_sensors):
        avg = (np.sum(corr_matrix[i]) - 1) / (num_sensors - 1)
        avg_corr.append(avg)
    avg_corr = np.array(avg_corr)
    min_index = np.argmin(avg_corr)
    sorted_corr = np.sort(avg_corr)
    if len(sorted_corr) > 1 and (sorted_corr[1] - sorted_corr[0] > threshold_diff):
        return sensor_names[min_index], avg_corr
    else:
        return None, avg_corr

# --------------------------
# Interpretation Function for Sensor Performance
# --------------------------
def interpret_sensor_performance(sensor_performance):
    """
    Interpret sensor performance metrics and print summary messages.
    """
    print("\n--- Interpretation of Sensor Performance ---")
    risk_levels = {sensor: metrics['risk_level'] for sensor, metrics in sensor_performance.items()}
    trends = {sensor: metrics['trend'] for sensor, metrics in sensor_performance.items()}
    sil_scores = {sensor: metrics['silhouette_score'] for sensor, metrics in sensor_performance.items()}

    avg_risk = np.mean(list(risk_levels.values()))
    std_risk = np.std(list(risk_levels.values()))
    avg_trend = np.mean(list(trends.values()))
    std_trend = np.std(list(trends.values()))

    for sensor, metrics in sensor_performance.items():
        msg = f"{sensor}: "
        if metrics['risk_level'] > avg_risk + 2 * std_risk:
            msg += "Risk level is significantly higher than average. "
        if metrics['trend'] > avg_trend + 2 * std_trend:
            msg += "Trend is exceptionally high, indicating abrupt changes. "
        if metrics['silhouette_score'] < 0.9:
            msg += "Silhouette score is lower than expected. "
        if msg == f"{sensor}: ":
            msg += "Performance appears consistent with other sensors."
        print(msg)

# --------------------------
# Main Anomaly Detection Pipeline
# --------------------------
def main_anomaly_detection(file_paths, tune_sensors=False, save_fig=True, save_dir=SAVE_DIR):
    misalignment_data = parse_sensor_data(file_paths[0])
    data_with_damper = parse_sensor_data(file_paths[1])
    data_without_damper = parse_sensor_data(file_paths[2])

    sensor_results = {}
    sensor_names = ['Sensor 1', 'Sensor 2', 'Sensor 3', 'Sensor 4']
    param_grid = {
        'dense_units': [64, 128],
        'dropout_rate': [0.2, 0.3],
        'learning_rate': [0.0003, 0.001],
        'epochs': [150, 300]
    } if tune_sensors else None

    for sensor_name in sensor_names:
        train_data = np.concatenate([
            data_with_damper[sensor_name],
            data_without_damper[sensor_name]
        ], axis=0)
        test_data = misalignment_data[sensor_name]
        print(f"\nProcessing {sensor_name} ...")
        detector = AnomalyDetector(sensor_name, train_data, test_data, tune=tune_sensors, param_grid=param_grid)
        reconstructed = detector.run()
        sensor_results[sensor_name] = {
            'test_data': test_data,
            'reconstructed': reconstructed,
            'detector': detector
        }

    sensor_performance = {}
    for sensor_name, results in sensor_results.items():
        detector = results['detector']
        metrics = SituationAwareness.calculate_metrics(detector.reconstruction_errors, detector.anomalies, detector.threshold)
        sensor_performance[sensor_name] = metrics
        # Plot reconstruction errors and multi-panel visualization.
        plot_reconstruction_errors(results['test_data'], results['reconstructed'], sensor_name, save_fig=save_fig, save_dir=save_dir)
        SituationAwareness.visualize_results(results['test_data'], results['reconstructed'],
                                               detector.reconstruction_errors,
                                               detector.anomalies,
                                               sensor_name, metrics,
                                               training_params=detector.best_params,
                                               save_fig=save_fig, save_dir=save_dir)
        # Visualize training history.
        if detector.history is not None:
            visualize_training_history(detector.history, sensor_name, save_fig=save_fig, save_dir=save_dir)
        # Visualize latent space (using normalized test data).
        visualize_latent_space(detector.autoencoder, detector.normalized_test, detector.anomalies, sensor_name, save_fig=save_fig, save_dir=save_dir)

    print("\n--- Sensor Performance ---")
    for sensor, metrics in sensor_performance.items():
        print(f"{sensor}:")
        for key, value in metrics.items():
            print(f"  {key}: {value:.4f}")
        print()

    interpret_sensor_performance(sensor_performance)
    sensor_names_list, corr_matrix = compute_sensor_cross_correlation(sensor_results)
    plot_cross_correlation(sensor_names_list, corr_matrix, save_fig=save_fig, save_dir=save_dir)
    malfunctioning_sensor, avg_corr = detect_malfunctioning_sensor(corr_matrix, sensor_names_list, threshold_diff=0.2)
    if malfunctioning_sensor is not None:
        print(f"Alert: {malfunctioning_sensor} is malfunctioning based on cross-correlation analysis.")
    else:
        print("All sensors are consistent based on cross-correlation analysis.")

    return sensor_performance

# --------------------------
# Run the Pipeline
# --------------------------
file_paths = [
    "/content/lift misalignment.txt",    # Test data
    "/content/lift with damper.txt",       # Training data
    "/content/lift without damper.txt"     # Training data
]

# Set tune_sensors=True to enable sensor-specific hyperparameter tuning.
main_anomaly_detection(file_paths, tune_sensors=True, save_fig=True, save_dir=SAVE_DIR)
